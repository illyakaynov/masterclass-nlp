{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<a href=\"https://vbti.nl\"><img src=\"./vbti_logo.png\" width=\"400\"></a>\n",
    "</div>\n",
    "\n",
    "# IMDB - Preprocessing\n",
    "\n",
    "In this example we are going to make a model to predict movies scores (negative, positive) based on user reviews.\n",
    "\n",
    "## Download dataset\n",
    "For this notebook we're going to use a dataset with movie reviews from the [Internet Movie Database (IMDB)](www.imdb.com). This dataset can be downloaded in different formats from different places. We use the dataset from [this Kaggle page](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews). Kaggle is a datascience competition website. To download the dataset you need an account, which can be created freely. Once the dataset is downloaded unzip it. \n",
    "\n",
    "To quote from the Kaggle page, the dataset contains the following information:\n",
    "\n",
    "The labeled data set consists of 50,000 IMDB movie reviews, specially selected for sentiment analysis. The sentiment of reviews is binary, meaning the IMDB rating < 5 results in a sentiment score of 0, and rating >=7 have a sentiment score of 1. No individual movie has more than 30 reviews. \n",
    "\n",
    "### Data fields\n",
    "- **sentiment** - Sentiment of the review; 'positive' for positive reviews and 'negative' for negative reviews\n",
    "- **review** - Text of the review\n",
    "\n",
    "Rename the unzipped csv file to 'IMDB.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# load some common libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# read IMBD reviews\n",
    "data = pd.read_csv('./IMDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does this dataset look like?\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have in total: 50000 reviews\n",
      "We have 25000 postive reviews\n",
      "we have 25000 negative reviews\n"
     ]
    }
   ],
   "source": [
    "# show size of dataframe\n",
    "print(\"We have in total: {} reviews\".format(len(data)))\n",
    "print(\"We have {} postive reviews\".format(len(data[data.sentiment==\"positive\"])))\n",
    "print(\"we have {} negative reviews\".format(len(data[data.sentiment==\"negative\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do the reviews look like?\n",
    "Movie reviews on the IMBd site are ranked with a 10-points scale, with `0` bad and `10` good. The reviews in our dataset are binary, that is, `0` for a low movie review (less than 5 IMBd score) and `1` for a high movie review (higher than 6 IMBd score).\n",
    "\n",
    "To see with what data we are dealing with, we inspect some reviews by hand first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The: 0'th review, this review is: positive.\n",
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
      "\n",
      "The: 1'th review, this review is: positive.\n",
      "A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\n",
      "\n",
      "The: 2'th review, this review is: positive.\n",
      "I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.\n"
     ]
    }
   ],
   "source": [
    "# Let's print a few reviews:\n",
    "for review in range(3):\n",
    "    print(\"\\nThe: {}'th review, this review is: {}.\".format(review, data.iloc[review][\"sentiment\"]))\n",
    "    print(data.iloc[review][\"review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning of the data.\n",
    "As you just saw, the reviews have all kinds of different shapes. We are going to do the following things for preprocessing (for each different review).\n",
    " 1. Converting the string sentiment to integers (0 for negative and 1 for positive)\n",
    " 2. Remove the html markup symbols (like `<br/>`). For this purpose we will use the python package `BeautifulSoup`.\n",
    " 3. Remove the stopwords (e.g. the, is). For this we will use the package `nltk` (Natural Language TookKit)  \n",
    " 4. Convert all capital letters to lower case. For this we will, also, use the module `nltk`.\n",
    " 5. remove non-characters and 1- and 2- letter words. For this, we will use the module `re` (regular expressions).\n",
    "\n",
    "The function `clean_text()` takes as input a review and performs the steps 2-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 1. convert string sentiment labels to integer values\n",
    "data['sentiment'] = data['sentiment'].apply(lambda sentiment:0 if sentiment=='negative' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already satisfied: BeautifulSoup4 in /opt/conda/lib/python3.7/site-packages (4.8.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /opt/conda/lib/python3.7/site-packages (from BeautifulSoup4) (1.9.4)\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "# If these packages are not yet installed you can download and install them by running this cell.\n",
    "!pip install BeautifulSoup4\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# impor the required packages:\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And download the stopswords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    # 2. Remove html markup\n",
    "    html_free_text = BeautifulSoup(s).get_text()\n",
    "    \n",
    "    # 5. Remove non-letters\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "                          \" \",                   # The pattern to replace it with\n",
    "                          html_free_text )       # The text to search\n",
    "\n",
    "    # 4. Split into lower-case words\n",
    "    lower_case = letters_only.lower()\n",
    "    words = lower_case.split()\n",
    "    \n",
    "    # 3. Remove stop words\n",
    "    # 5. Remove all words with 2 or 1 letters\n",
    "    words = [w for w in words if (not w in stopwords.words(\"english\")) and (len(w)>2)]\n",
    "    \n",
    "    # 6. Return words as a single string again\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing 0/50000\n",
      "Doing 1000/50000\n",
      "Doing 2000/50000\n",
      "Doing 3000/50000\n",
      "Doing 4000/50000\n",
      "Doing 5000/50000\n",
      "Doing 6000/50000\n",
      "Doing 7000/50000\n",
      "Doing 8000/50000\n",
      "Doing 9000/50000\n",
      "Doing 10000/50000\n",
      "Doing 11000/50000\n",
      "Doing 12000/50000\n",
      "Doing 13000/50000\n",
      "Doing 14000/50000\n",
      "Doing 15000/50000\n",
      "Doing 16000/50000\n",
      "Doing 17000/50000\n",
      "Doing 18000/50000\n"
     ]
    }
   ],
   "source": [
    "# process all reviews\n",
    "labels = []\n",
    "reviews = []\n",
    "\n",
    "for i, (_, row) in enumerate(data.iterrows()):\n",
    "    if i%1000==0:\n",
    "        # show progress\n",
    "        print(f'Doing {i}/{data.shape[0]}')\n",
    "    labels.append(row['sentiment'])\n",
    "    reviews.append(clean_text(row['review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's print some reviews again:\n",
    "for review in range(3):\n",
    "    print(\"\\nThe: {}'th review, this review is: {}.\".format(review, data.iloc[review][\"sentiment\"]))\n",
    "    print(data.iloc[review][\"review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into a test and train part.\n",
    "To measure the goodness of a model we will hold back a part of the whole dataset (`test_data`). After a model is trained on the rest of the whole dataset (`train_data`) we can test the accuracy on the unseen `test_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "split = 0.5\n",
    "\n",
    "train_data = (reviews[:int(split*len(reviews))], labels[:int(split*len(labels))])\n",
    "test_data  = (reviews[int((1-split)*len(reviews)):], labels[int((1-split)*len(labels)):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best practices, serializing with `pickle`\n",
    "As you might notice, reading and cleaning the text files takes a long time. In production environments you would like to parallellize the complete task. For now, we are going to save the python tuples `train_data` and `test_data` into a Python pickle object. Python's `pickle` module is used to (de)serialize python objects to file. This way, objects can be shared between different Python programs and/or time is saved to create an object as in our case. A nice tutorial on using the pickle module can be found [here](https://www.datacamp.com/community/tutorials/pickle-python-tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = './train_data.pickle'\n",
    "with open(filename, 'wb') as file_object:\n",
    "    pickle.dump(train_data, file_object)\n",
    "    \n",
    "filename = './test_data.pickle'\n",
    "with open(filename, 'wb') as file_object:\n",
    "    pickle.dump(test_data, file_object)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the pickle files the follow code can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# read pickle files\n",
    "import pickle\n",
    "\n",
    "filename = './train_data.pickle'\n",
    "with open(filename, 'rb') as file_object:\n",
    "    train_data = pickle.load(file_object)\n",
    "    \n",
    "filename = './test_data.pickle'\n",
    "with open(filename, 'rb') as file_object:\n",
    "    test_data = pickle.load(file_object)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
