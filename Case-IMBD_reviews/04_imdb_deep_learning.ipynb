{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<a href=\"https://vbti.nl\"><img src=\"./vbti_logo.png\" width=\"400\"></a>\n",
    "</div>\n",
    "\n",
    "# IMBD - Deep Learning\n",
    "\n",
    "In this notebook we continue with the IMDB dataset and start building deep learning models to predict the movie score.\n",
    "\n",
    "It contains the following sections:\n",
    " 1. Converting the reviews to word embeddings, again, with the `Word2Vec` class.\n",
    " 2. We will build, train and evaluate three different architectures:\n",
    "  - A Multilayer perceptron, this is (as discussed in the masterclass) the most basic neural network.\n",
    "  - A 1D dimensional convolutional neural network (CNN).\n",
    "  - A simple recurrent neural network.\n",
    "  - A LSTM.\n",
    "  - A bidirectional LSTM.\n",
    "    \n",
    "    Al these networks are build with the package `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some common libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pickle files\n",
    "import pickle\n",
    "\n",
    "filename = './train_data.pickle'\n",
    "with open(filename, 'rb') as file_object:\n",
    "    train_data = pickle.load(file_object)\n",
    "    \n",
    "filename = './test_data.pickle'\n",
    "with open(filename, 'rb') as file_object:\n",
    "    test_data = pickle.load(file_object)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for gensim\n",
    "# data needs to be presented as a list of list of words\n",
    "sentences = []\n",
    "for review in train_data[0]:\n",
    "    sentences.append(review.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector-space embedding\n",
    "n_embed_dim = 128\n",
    "n_context = 3\n",
    "\n",
    "# (maximum) size of review as input for deep nn model\n",
    "n_input_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model_w2v = Word2Vec(sentences, size=n_embed_dim, window=n_context, min_count=10, workers=4)\n",
    "model_w2v.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_w2v_dl(model_w2v, sentences, n_input_dim, n_embed_dim):\n",
    "    n_train_samples = len(sentences)\n",
    "    wv = np.zeros((n_train_samples, n_input_dim, n_embed_dim))\n",
    "\n",
    "    for i in range(n_train_samples):\n",
    "        sentence = sentences[i]\n",
    "        n_words = len(sentence)\n",
    "\n",
    "        if n_words > n_input_dim:\n",
    "            for j, w in enumerate(sentence[0:n_input_dim]):\n",
    "                try:\n",
    "                    vec = model_w2v.wv[w]\n",
    "                    wv[i,j,:] = vec\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        else:\n",
    "            start = (n_input_dim - n_words) // 2\n",
    "            for j, w in enumerate(sentence[0:n_input_dim]):\n",
    "                try:\n",
    "                    vec = model_w2v.wv[w]\n",
    "                    wv[i,start+j,:] = vec\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    return wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = featurize_w2v_dl(model_w2v, sentences, n_input_dim, n_embed_dim)\n",
    "y_train = np.array(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for review in test_data[0]:\n",
    "    sentences.append(review.split(' '))\n",
    "X_test = featurize_w2v_dl(model_w2v, sentences, n_input_dim, n_embed_dim)\n",
    "y_test = np.array(test_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building\n",
    "\n",
    "Define some handy utility functions to plot model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, \n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          ax=None,\n",
    "                          figsize=(8,8)):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if ax==None:\n",
    "        _, ax = plt.subplot(1, 1, figsize=figsize)\n",
    "        \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.set_title(title, pad=20)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_yticklabels(classes)\n",
    "    ax.grid(False)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i, \n",
    "                format(cm[i, j], fmt),\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')    \n",
    "    ax.set_ylim((len(classes) - 0.5, -0.5))\n",
    "\n",
    "    \n",
    "def accuracy(y, y_pred):\n",
    "    return np.sum(y==y_pred)/len(y)\n",
    "\n",
    "\n",
    "def plot_model_performance(model, X_train, y_train, X_test, y_test, label_names, figsize=(8,6)):\n",
    "    \"\"\"Support function for quickly plotting model performance.\"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=figsize)\n",
    "    axs.ravel()\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    plot_confusion_matrix(cm_train, \n",
    "                          list(label_names), \n",
    "                          title='Training - accuracy: {:.2f}'.format(accuracy(y_train, y_train_pred)),\n",
    "                          ax=axs[0])\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "    plot_confusion_matrix(cm_test, \n",
    "                          list(label_names), \n",
    "                          title='Test - accuracy: {:.2f}'.format(accuracy(y_test, y_test_pred)),\n",
    "                          ax=axs[1])\n",
    "\n",
    "    plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select GPU on VBTI server\n",
    "# import os\n",
    "# GPU = \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8 MB 73.5 MB/s eta 0:00:01  |▌                               | 6.5 MB 3.1 MB/s eta 0:02:1509                       | 40.3 MB 47.7 MB/s eta 0:00:09     |████                            | 51.7 MB 47.7 MB/s eta 0:00:08     |██████████                      | 131.5 MB 72.9 MB/s eta 0:00:04     |██████████▏                     | 134.1 MB 72.9 MB/s eta 0:00:04     |███████████████▌                | 203.8 MB 50.0 MB/s eta 0:00:05"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras) (1.17.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras) (1.14.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras) (5.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "n_dense = 256\n",
    "dropout = 0.2\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(n_input_dim, n_embed_dim)))\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               3277056   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,277,313\n",
      "Trainable params: 3,277,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.4664 - accuracy: 0.7784 - val_loss: 0.4392 - val_accuracy: 0.7926\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 43s 2ms/step - loss: 0.3559 - accuracy: 0.8409 - val_loss: 0.4363 - val_accuracy: 0.7984\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2700 - accuracy: 0.8846 - val_loss: 0.4700 - val_accuracy: 0.7922\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 43s 2ms/step - loss: 0.1621 - accuracy: 0.9437 - val_loss: 0.5325 - val_accuracy: 0.7872\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.0660 - accuracy: 0.9838 - val_loss: 0.6297 - val_accuracy: 0.7791\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 43s 2ms/step - loss: 0.0258 - accuracy: 0.9961 - val_loss: 0.7346 - val_accuracy: 0.7870\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.0122 - accuracy: 0.9991 - val_loss: 0.8473 - val_accuracy: 0.7878\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 43s 2ms/step - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.9147 - val_accuracy: 0.7871\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.0049 - accuracy: 0.9998 - val_loss: 0.9389 - val_accuracy: 0.7860\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.9730 - val_accuracy: 0.7870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff49c874a90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9cd863d4085f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'negative'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-78d5ae9a0aac>\u001b[0m in \u001b[0;36mplot_model_performance\u001b[0;34m(model, X_train, y_train, X_test, y_test, label_names, figsize)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mcm_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     plot_confusion_matrix(cm_train, \n\u001b[1;32m     59\u001b[0m                           \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_performance(model, X_train, y_train, X_test, y_test, ['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kernels = 256\n",
    "kernel_size = 3\n",
    "\n",
    "n_dense = 256\n",
    "dropout = 0.2\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(n_kernels, kernel_size, activation='relu', input_shape=(n_input_dim, n_embed_dim)))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = featurize_w2v_dl(model_w2v, ['nice movie and i really liked the end'.split()], n_input_dim, n_embed_dim)\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = featurize_w2v_dl(model_w2v, ['this was a waste of time a terrible movie'.split()], n_input_dim, n_embed_dim)\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(model, X_train, y_train, X_test, y_test, ['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "n_rnn = 256\n",
    "drop_rnn = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(SimpleRNN(n_rnn, dropout=drop_rnn, activation='relu', input_shape=(None, n_embed_dim)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(model, X_train, y_train, X_test, y_test, ['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "n_lstm = 256\n",
    "drop_lstm = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(n_lstm, dropout=drop_lstm, activation='relu', input_shape=(None, n_embed_dim)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.00001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=10, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(model, X_train, y_train, X_test, y_test, ['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(n_rnn, dropout=drop_rnn, activation='relu'), input_shape=(None, n_embed_dim)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.00001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(model, X_train, y_train, X_test, y_test, ['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
